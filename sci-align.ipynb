{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c0ab7b-c6b3-45fd-bc27-0099d3280d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from concurrent import futures\n",
    "\n",
    "from whoswho import who\n",
    "from pypinyin import pinyin\n",
    "from pinyinsplit import PinyinSplit\n",
    "from rich.progress import Progress, BarColumn, SpinnerColumn\n",
    "\n",
    "pys = PinyinSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d50565ae-3e03-4ee1-aa05-81c1f1c54741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "\n",
    "def parse(file):\n",
    "    results = []\n",
    "    df = pd.read_excel(file, header=None)\n",
    "    dfs = np.split(df, df[df.isnull().all(1)].index)\n",
    "    for dfc in dfs:\n",
    "        result = {}\n",
    "        dfc[0].fillna(method=\"pad\", inplace=True)\n",
    "        # process authors\n",
    "        dfn = dfc.loc[dfc[0] == \"AU\"].iloc[:, 1:3]\n",
    "        dfnf = dfn.iloc[:, 0] + dfn.iloc[:, 1]\n",
    "        result[\"AU\"] = dfnf.to_list()\n",
    "        # process title\n",
    "        titles_segs = []\n",
    "        dft = dfc.loc[dfc[0] == \"TI\"].iloc[:, 1:3]\n",
    "        for i, r in dft.iterrows():\n",
    "            titles_segs.extend(r.dropna().to_list())\n",
    "        result[\"TI\"] = \" \".join([s.strip() for s in titles_segs])\n",
    "        if not result[\"AU\"] or not result[\"TI\"]:\n",
    "            continue\n",
    "        else:\n",
    "            result[\"CI\"] = file\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def is_all_chinese(s):\n",
    "    for _char in s:\n",
    "        if not \"\\u4e00\" <= _char <= \"\\u9fa5\":\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def mutate_comb(comb):\n",
    "    results = [\" \".join(comb).title()]\n",
    "    if len(comb) == 2:\n",
    "        results.append(f\"{comb[1]} {comb[0]}\".title())\n",
    "    elif len(comb) == 3:\n",
    "        results.append(f\"{comb[1]} {comb[2]} {comb[0]}\".title())\n",
    "        results.append(f\"{comb[1]}{comb[2]} {comb[0]}\".title())\n",
    "        results.append(f\"{comb[0]} {comb[1]}{comb[2]}\".title())\n",
    "    elif len(comb) == 4:\n",
    "        results.append(f\"{comb[2]} {comb[3]} {comb[0]} {comb[1]}\".title())\n",
    "        results.append(f\"{comb[0]}{comb[1]} {comb[2]}{comb[3]} \".title())\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_alternatives(s):\n",
    "    results = [s]\n",
    "    words = s.split()\n",
    "    if is_all_chinese(s):\n",
    "        combs = pinyin(s, heteronym=True, style=0)\n",
    "        for comb in itertools.product(*combs):\n",
    "            results.extend(mutate_comb(comb))\n",
    "    elif len(words) == 2:\n",
    "        splits = [pys.split(x) for x in reversed(words)]\n",
    "        if all(splits):\n",
    "            for comb in itertools.product(*splits):\n",
    "                comb = [item for sublist in comb for item in sublist]\n",
    "                results.extend(mutate_comb(comb))\n",
    "    if words[0].isupper():\n",
    "        result = \"\"\n",
    "        for ss in words[0]:\n",
    "            result += f\"{ss}. \"\n",
    "        result += \" \".join(words[1:])\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def pinyin_sanity_check(a, b):\n",
    "    a = \"\".join(filter(str.isalpha, a.lower()))\n",
    "    b = \"\".join(filter(str.isalpha, b.lower()))\n",
    "    a = [set(x) for x in pys.split(a)]\n",
    "    b = [set(x) for x in pys.split(b)]\n",
    "    if not a or not b:\n",
    "        return True\n",
    "    for ai in a:\n",
    "        if ai in b:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def align(nl):\n",
    "    results = []\n",
    "    for n in nl:\n",
    "        for nln, nlf in name_lists.items():\n",
    "            for nf in nlf:\n",
    "                alters = itertools.product(get_alternatives(n), get_alternatives(nf))\n",
    "                if any((who.match(*args) for args in alters)):\n",
    "                    results.append((n, nln, nf))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032ba09a-d9e0-465d-a52f-c5654c776111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whoswho failed: \"Ching-Hong Pui\" and \"Ching Hon Pui\" == True \n"
     ]
    }
   ],
   "source": [
    "# test methods\n",
    "test_pairs = [\n",
    "    (\"Pierre Tiollais\", \"Pierre T.\", False),\n",
    "    (\"Colin Blakemore\", \"Colin B\", False),\n",
    "    (\"Hideaki Koizumi\", \"H. Koizumi\", True),\n",
    "    (\"Hideaki Koizakala\", \"Hideaki Koizumi\", False),\n",
    "    (\"Hideaki Koiza\", \"Hideaki Koizakala\", False),\n",
    "    (\"Hideaki Koizumi\", \"H Koizumi\", True),\n",
    "    (\"Barry J. Marshall\", \"Barry J Marshall\", True),\n",
    "    (\"Barry J. Marshall\", \"Barry Jackson Marshall\", True),\n",
    "    (\"Barry Jackson Marshall\", \"B. J. Marshall\", True),\n",
    "    (\"Barry Jackson Marshall\", \"BJ Marshall\", True),\n",
    "    (\"Barry Jackson Marshall\", \"B. Marshall\", True),\n",
    "    (\"Barry Jackson Marshall\", \"B. Mardave\", False),\n",
    "    (\"Barry J. Marshall\", \"Barry Marshall\", True),\n",
    "    (\"Barry Marshall\", \"Barry J. Marshall\", True),\n",
    "    (\"Henry T. Y. Yang\", \"Henry T. Yang\", False),\n",
    "    (\"Henry T. Yang\", \"Henry T. Y. Yang\", False),\n",
    "    (\"Ching-Hon Pui\", \"Ching Hon Pui\", True),\n",
    "    (\"Ching-Hong Pui\", \"Ching Hon Pui\", False),\n",
    "    (\"Ching-Hon Pui\", \"Ching-Hon Tui\", False),\n",
    "    (\"周哲晟\", \"Zhesheng Zhou\", True),\n",
    "    (\"周哲晟\", \"Zhou Zhesheng\", True),\n",
    "    (\"周哲晟\", \"Zhou, Zhesheng\", True),\n",
    "    (\"周哲晟\", \"ZS Zhou\", True),\n",
    "    (\"周哲晟\", \"Z. S. Zhou\", True),\n",
    "    (\"周哲晟\", \"Zhou Z. S.\", False),\n",
    "    (\"周哲晟\", \"Zhesheng Z.\", False),\n",
    "    (\"周哲晟\", \"Zhe-sheng Zhou\", True),\n",
    "    (\"周哲晟啊\", \"Zhou Z. S.\", False),\n",
    "    (\"周哲\", \"Zhou Z. S.\", False),\n",
    "    (\"周哲\", \"Zhou Zhe\", True),\n",
    "    (\"周哲\", \"Zhe Zhou\", True),\n",
    "    (\"周王\", \"Zhou Z. S.\", False),\n",
    "    (\"Zhesheng Zhou\", \"Zhou, Zhesheng\", True),\n",
    "    (\"Zhesheng Zhou\", \"Zhou, Zhe-sheng\", True),\n",
    "    (\"Zhesheng Zhou\", \"Zesi Zhou\", False),\n",
    "    (\"Zhou Zhesheng\", \"Zhou, Zhesheng\", True),\n",
    "    (\"Zhe Sheng Zhou\", \"Zhou, Zhesheng\", True),\n",
    "    (\"Zhesheng Zhou\", \"Zhesheng Zhou\", True),\n",
    "    (\"Zhesheng Zhou\", \"Zhe-sheng Zhou\", True),\n",
    "    (\"Zhesheng Zhou\", \"ZS Zhou\", True),\n",
    "    (\"Zhesheng Zhou\", \"Z. Zhou\", True),\n",
    "    (\"Zhesheng Zhou\", \"Zhou Zhezhe\", False),\n",
    "    (\"Zhesheng Zhou\", \"Z. S. Zhou\", True),\n",
    "    (\"Zheshe Zhou\", \"Zhou Zhesheng\", False),\n",
    "    (\"Wang Xian\", \"Zhu Yuxian\", False),\n",
    "]\n",
    "\n",
    "for p in test_pairs:\n",
    "    alters = itertools.product(get_alternatives(p[0]), get_alternatives(p[1]))\n",
    "    who_matched = any(\n",
    "        (who.match(*args) and pinyin_sanity_check(*args) for args in alters)\n",
    "    )\n",
    "    if who_matched != p[2]:\n",
    "        print(f'whoswho failed: \"{p[0]}\" and \"{p[1]}\" == {who_matched} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5df2ef1-12fe-467c-b4fa-3a12d82e9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "cpus = 2\n",
    "cites_dir = \"./data/cites\"\n",
    "name_list_files = {\n",
    "    \"Chinese Academicians\": \"./data/chinese_academicians.txt\",\n",
    "    \"Foreign Academicians\": \"./data/foreign_academicians.txt\",\n",
    "    \"Foreign Academicians (Chinese)\": \"./data/foreign_academicians_chinese.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845f50b-9dbb-48a4-a0b7-a9608b1eedb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84c54e833a642e0ac29355fe79cad7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read name lists\n",
    "name_lists = {}\n",
    "for nln, nlf in name_list_files.items():\n",
    "    with open(nlf, 'r') as f:\n",
    "        name_lists[nln] = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "# read cite files\n",
    "targets = list(Path(cites_dir).glob(\"*.xlsx\"))\n",
    "results = []\n",
    "progress = Progress(\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    \"[progress.percentage]{task.percentage:>3.0f}%\",\n",
    "    \"{task.completed}/{task.total}\",\n",
    "    SpinnerColumn()\n",
    ")\n",
    "with progress:\n",
    "    with futures.ProcessPoolExecutor(max_workers=cpus) as executor:\n",
    "        task1 = progress.add_task(\"Loading cite files...\", len(targets))\n",
    "        future_to_target = {executor.submit(parse, t): t for t in targets}\n",
    "        future_to_input = {}\n",
    "        for future in futures.as_completed(future_to_target):\n",
    "            target = future_to_target[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print(f'Error occors when processing \"{target}\":\\n\\t{exc}')\n",
    "            else:\n",
    "                for c in data:\n",
    "                    future_to_input[executor.submit(align, c[\"AU\"])] = c\n",
    "            finally:\n",
    "                progress.update(task1, advance=1)\n",
    "        task2 = progress.add_task(\"Processing...\", len(future_to_input))\n",
    "        for future in futures.as_completed(future_to_input):\n",
    "            inp = future_to_input[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                print(f'Error occors when processing \"{inp[\"TI\"]}\":\\n\\t{exc}')\n",
    "            else:\n",
    "                for m in data:\n",
    "                    results.append({\n",
    "                        \"Title\": inp[\"TI\"],\n",
    "                        \"Cited by\": inp[\"CI\"],\n",
    "                        \"Author\": m[0],\n",
    "                        \"Author Match Catalog\": m[1],\n",
    "                        \"Author Match\": m[2],\n",
    "                    })\n",
    "            finally:\n",
    "                progress.update(task2, advance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932deb7-b76d-45f3-b2b3-a19db27ca724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3283d0cd456f7f3a0259b48987e2bc60517172be2fbfaa351d9914cebf988b5e"
  },
  "kernelspec": {
   "display_name": "app-sci-align",
   "language": "python",
   "name": "app-sci-align"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
